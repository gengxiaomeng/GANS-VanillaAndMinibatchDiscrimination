{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from minibatch_discrimination import MiniBatchDiscrimination\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimensions for an MNIST image\n",
    "MNIST_W = 28\n",
    "MNIST_H = 28\n",
    "MNIST_DIM = MNIST_H*MNIST_W\n",
    "NOISE_DIM = 100\n",
    "BATCH_SIZE = 20\n",
    "LEARN_RATE = 1e-3\n",
    "MAX_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.0,),(1,))])\n",
    "trainset = torchvision.datasets.MNIST(root = '../data_MNIST',train = True, download = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator and discriminator networks\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.lin1 = nn.Linear(NOISE_DIM, 192)\n",
    "        self.lin2 = nn.Linear(192, MNIST_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.lin1(x),0.1)\n",
    "        # x = self.bat1(x)\n",
    "        x = F.sigmoid(self.lin2(x))\n",
    "        return x\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.lin1 = nn.Linear(MNIST_DIM, 128)\n",
    "        self.mbd1 = MiniBatchDiscrimination(128, 64, 50, BATCH_SIZE)\n",
    "        self.lin2 = nn.Linear(192, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.lin1(x),0.1)        \n",
    "        x = F.sigmoid(self.lin2( torch.cat((x, self.mbd1(x)),dim=1) ))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a generator and discriminator and start training\n",
    "smooth_labels = 1\n",
    "gen1 = Generator()\n",
    "dis1 = Discriminator()\n",
    "gen_optimizer = optim.Adam(gen1.parameters(), lr = LEARN_RATE)\n",
    "dis_optimizer = optim.Adam(dis1.parameters(), lr = LEARN_RATE)\n",
    "\n",
    "criterion_dis = nn.BCELoss()\n",
    "criterion_gen = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:   0 dis_loss: 1.382 gen_loss: 1.066  \n",
      "iter: 100 dis_loss: 0.922 gen_loss: 1.556  \n",
      "iter: 200 dis_loss: 0.694 gen_loss: 2.217  \n",
      "iter: 300 dis_loss: 0.688 gen_loss: 2.267  \n",
      "iter: 400 dis_loss: 0.669 gen_loss: 2.181  \n",
      "iter: 500 dis_loss: 0.668 gen_loss: 2.111  \n",
      "iter: 600 dis_loss: 0.659 gen_loss: 1.948  \n",
      "iter: 700 dis_loss: 0.656 gen_loss: 2.031  \n",
      "iter: 800 dis_loss: 0.660 gen_loss: 2.163  \n",
      "iter: 900 dis_loss: 0.736 gen_loss: 2.084  \n",
      "iter: 1000 dis_loss: 0.706 gen_loss: 2.291  \n",
      "iter: 1100 dis_loss: 0.664 gen_loss: 2.363  \n",
      "iter: 1200 dis_loss: 0.685 gen_loss: 2.149  \n",
      "iter: 1300 dis_loss: 0.666 gen_loss: 2.261  \n",
      "iter: 1400 dis_loss: 0.681 gen_loss: 2.142  \n",
      "iter: 1500 dis_loss: 0.698 gen_loss: 2.378  \n",
      "iter: 1600 dis_loss: 0.684 gen_loss: 2.376  \n",
      "iter: 1700 dis_loss: 0.682 gen_loss: 2.072  \n",
      "iter: 1800 dis_loss: 0.681 gen_loss: 2.106  \n",
      "iter: 1900 dis_loss: 0.694 gen_loss: 2.027  \n",
      "iter: 2000 dis_loss: 0.765 gen_loss: 2.011  \n",
      "iter: 2100 dis_loss: 0.675 gen_loss: 1.956  \n",
      "iter: 2200 dis_loss: 0.721 gen_loss: 1.932  \n",
      "iter: 2300 dis_loss: 0.753 gen_loss: 1.661  \n",
      "iter: 2400 dis_loss: 0.723 gen_loss: 1.805  \n",
      "iter: 2500 dis_loss: 0.720 gen_loss: 1.835  \n",
      "iter: 2600 dis_loss: 0.732 gen_loss: 1.973  \n",
      "iter: 2700 dis_loss: 0.700 gen_loss: 1.826  \n",
      "iter: 2800 dis_loss: 0.725 gen_loss: 2.015  \n",
      "iter: 2900 dis_loss: 0.768 gen_loss: 2.281  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 0.870 gen_loss: 1.404  \n",
      "iter: 100 dis_loss: 0.727 gen_loss: 1.705  \n",
      "iter: 200 dis_loss: 0.806 gen_loss: 1.574  \n",
      "iter: 300 dis_loss: 0.836 gen_loss: 1.813  \n",
      "iter: 400 dis_loss: 0.777 gen_loss: 1.844  \n",
      "iter: 500 dis_loss: 0.745 gen_loss: 2.296  \n",
      "iter: 600 dis_loss: 0.964 gen_loss: 1.589  \n",
      "iter: 700 dis_loss: 0.939 gen_loss: 1.748  \n",
      "iter: 800 dis_loss: 0.775 gen_loss: 1.862  \n",
      "iter: 900 dis_loss: 0.772 gen_loss: 1.818  \n",
      "iter: 1000 dis_loss: 0.849 gen_loss: 1.896  \n",
      "iter: 1100 dis_loss: 0.993 gen_loss: 2.071  \n",
      "iter: 1200 dis_loss: 0.875 gen_loss: 1.627  \n",
      "iter: 1300 dis_loss: 0.819 gen_loss: 1.790  \n",
      "iter: 1400 dis_loss: 0.886 gen_loss: 1.684  \n",
      "iter: 1500 dis_loss: 0.987 gen_loss: 1.615  \n",
      "iter: 1600 dis_loss: 1.017 gen_loss: 2.222  \n",
      "iter: 1700 dis_loss: 1.012 gen_loss: 1.779  \n",
      "iter: 1800 dis_loss: 0.985 gen_loss: 1.498  \n",
      "iter: 1900 dis_loss: 0.985 gen_loss: 1.516  \n",
      "iter: 2000 dis_loss: 0.869 gen_loss: 1.756  \n",
      "iter: 2100 dis_loss: 0.818 gen_loss: 1.590  \n",
      "iter: 2200 dis_loss: 0.942 gen_loss: 1.446  \n",
      "iter: 2300 dis_loss: 0.819 gen_loss: 1.419  \n",
      "iter: 2400 dis_loss: 0.909 gen_loss: 1.314  \n",
      "iter: 2500 dis_loss: 1.065 gen_loss: 1.614  \n",
      "iter: 2600 dis_loss: 0.970 gen_loss: 1.239  \n",
      "iter: 2700 dis_loss: 0.933 gen_loss: 1.734  \n",
      "iter: 2800 dis_loss: 0.820 gen_loss: 1.454  \n",
      "iter: 2900 dis_loss: 0.922 gen_loss: 1.632  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 0.967 gen_loss: 1.639  \n",
      "iter: 100 dis_loss: 0.895 gen_loss: 1.812  \n",
      "iter: 200 dis_loss: 1.009 gen_loss: 1.422  \n",
      "iter: 300 dis_loss: 0.862 gen_loss: 1.326  \n",
      "iter: 400 dis_loss: 0.878 gen_loss: 1.565  \n",
      "iter: 500 dis_loss: 1.025 gen_loss: 1.823  \n",
      "iter: 600 dis_loss: 0.975 gen_loss: 1.320  \n",
      "iter: 700 dis_loss: 0.862 gen_loss: 1.647  \n",
      "iter: 800 dis_loss: 0.992 gen_loss: 1.539  \n",
      "iter: 900 dis_loss: 1.062 gen_loss: 1.298  \n",
      "iter: 1000 dis_loss: 0.981 gen_loss: 1.529  \n",
      "iter: 1100 dis_loss: 0.957 gen_loss: 1.380  \n",
      "iter: 1200 dis_loss: 1.026 gen_loss: 1.358  \n",
      "iter: 1300 dis_loss: 0.884 gen_loss: 1.477  \n",
      "iter: 1400 dis_loss: 0.935 gen_loss: 1.282  \n",
      "iter: 1500 dis_loss: 0.919 gen_loss: 1.528  \n",
      "iter: 1600 dis_loss: 0.878 gen_loss: 2.173  \n",
      "iter: 1700 dis_loss: 1.045 gen_loss: 1.553  \n",
      "iter: 1800 dis_loss: 1.029 gen_loss: 1.339  \n",
      "iter: 1900 dis_loss: 0.950 gen_loss: 1.461  \n",
      "iter: 2000 dis_loss: 0.949 gen_loss: 1.387  \n",
      "iter: 2100 dis_loss: 1.077 gen_loss: 1.514  \n",
      "iter: 2200 dis_loss: 1.211 gen_loss: 1.176  \n",
      "iter: 2300 dis_loss: 0.932 gen_loss: 1.309  \n",
      "iter: 2400 dis_loss: 0.992 gen_loss: 1.632  \n",
      "iter: 2500 dis_loss: 1.247 gen_loss: 1.462  \n",
      "iter: 2600 dis_loss: 1.136 gen_loss: 1.332  \n",
      "iter: 2700 dis_loss: 1.016 gen_loss: 1.959  \n",
      "iter: 2800 dis_loss: 1.134 gen_loss: 1.212  \n",
      "iter: 2900 dis_loss: 1.082 gen_loss: 1.230  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 0.887 gen_loss: 1.254  \n",
      "iter: 100 dis_loss: 0.884 gen_loss: 1.956  \n",
      "iter: 200 dis_loss: 1.193 gen_loss: 1.411  \n",
      "iter: 300 dis_loss: 1.108 gen_loss: 1.393  \n",
      "iter: 400 dis_loss: 0.963 gen_loss: 1.367  \n",
      "iter: 500 dis_loss: 0.896 gen_loss: 1.404  \n",
      "iter: 600 dis_loss: 1.044 gen_loss: 1.402  \n",
      "iter: 700 dis_loss: 1.052 gen_loss: 1.211  \n",
      "iter: 800 dis_loss: 0.954 gen_loss: 1.310  \n",
      "iter: 900 dis_loss: 0.945 gen_loss: 1.310  \n",
      "iter: 1000 dis_loss: 1.151 gen_loss: 1.540  \n",
      "iter: 1100 dis_loss: 1.105 gen_loss: 1.264  \n",
      "iter: 1200 dis_loss: 1.295 gen_loss: 2.068  \n",
      "iter: 1300 dis_loss: 0.984 gen_loss: 1.196  \n",
      "iter: 1400 dis_loss: 0.924 gen_loss: 1.406  \n",
      "iter: 1500 dis_loss: 0.926 gen_loss: 1.228  \n",
      "iter: 1600 dis_loss: 1.351 gen_loss: 1.406  \n",
      "iter: 1700 dis_loss: 0.989 gen_loss: 1.510  \n",
      "iter: 1800 dis_loss: 1.037 gen_loss: 1.390  \n",
      "iter: 1900 dis_loss: 0.977 gen_loss: 1.297  \n",
      "iter: 2000 dis_loss: 0.994 gen_loss: 1.253  \n",
      "iter: 2100 dis_loss: 1.082 gen_loss: 1.361  \n",
      "iter: 2200 dis_loss: 1.000 gen_loss: 1.241  \n",
      "iter: 2300 dis_loss: 0.906 gen_loss: 1.380  \n",
      "iter: 2400 dis_loss: 1.079 gen_loss: 1.455  \n",
      "iter: 2500 dis_loss: 0.972 gen_loss: 1.696  \n",
      "iter: 2600 dis_loss: 1.264 gen_loss: 1.007  \n",
      "iter: 2700 dis_loss: 1.041 gen_loss: 1.389  \n",
      "iter: 2800 dis_loss: 0.929 gen_loss: 1.408  \n",
      "iter: 2900 dis_loss: 1.083 gen_loss: 1.395  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.137 gen_loss: 1.400  \n",
      "iter: 100 dis_loss: 1.178 gen_loss: 1.354  \n",
      "iter: 200 dis_loss: 1.106 gen_loss: 1.172  \n",
      "iter: 300 dis_loss: 1.094 gen_loss: 1.328  \n",
      "iter: 400 dis_loss: 0.987 gen_loss: 1.385  \n",
      "iter: 500 dis_loss: 1.244 gen_loss: 1.507  \n",
      "iter: 600 dis_loss: 0.994 gen_loss: 1.779  \n",
      "iter: 700 dis_loss: 0.990 gen_loss: 0.974  \n",
      "iter: 800 dis_loss: 1.204 gen_loss: 1.568  \n",
      "iter: 900 dis_loss: 0.997 gen_loss: 1.446  \n",
      "iter: 1000 dis_loss: 1.166 gen_loss: 1.048  \n",
      "iter: 1100 dis_loss: 1.178 gen_loss: 1.375  \n",
      "iter: 1200 dis_loss: 1.129 gen_loss: 1.231  \n",
      "iter: 1300 dis_loss: 1.215 gen_loss: 1.023  \n",
      "iter: 1400 dis_loss: 1.096 gen_loss: 1.180  \n",
      "iter: 1500 dis_loss: 1.097 gen_loss: 2.008  \n",
      "iter: 1600 dis_loss: 1.135 gen_loss: 1.282  \n",
      "iter: 1700 dis_loss: 1.147 gen_loss: 1.796  \n",
      "iter: 1800 dis_loss: 0.993 gen_loss: 1.316  \n",
      "iter: 1900 dis_loss: 0.999 gen_loss: 1.783  \n",
      "iter: 2000 dis_loss: 0.996 gen_loss: 1.321  \n",
      "iter: 2100 dis_loss: 1.042 gen_loss: 1.253  \n",
      "iter: 2200 dis_loss: 1.085 gen_loss: 1.301  \n",
      "iter: 2300 dis_loss: 0.999 gen_loss: 1.034  \n",
      "iter: 2400 dis_loss: 1.010 gen_loss: 1.305  \n",
      "iter: 2500 dis_loss: 1.296 gen_loss: 1.301  \n",
      "iter: 2600 dis_loss: 1.048 gen_loss: 1.113  \n",
      "iter: 2700 dis_loss: 1.068 gen_loss: 1.147  \n",
      "iter: 2800 dis_loss: 0.899 gen_loss: 1.048  \n",
      "iter: 2900 dis_loss: 1.074 gen_loss: 1.276  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.085 gen_loss: 1.373  \n",
      "iter: 100 dis_loss: 1.275 gen_loss: 1.045  \n",
      "iter: 200 dis_loss: 1.097 gen_loss: 1.189  \n",
      "iter: 300 dis_loss: 1.100 gen_loss: 1.210  \n",
      "iter: 400 dis_loss: 1.193 gen_loss: 1.048  \n",
      "iter: 500 dis_loss: 1.056 gen_loss: 1.289  \n",
      "iter: 600 dis_loss: 1.127 gen_loss: 1.369  \n",
      "iter: 700 dis_loss: 1.137 gen_loss: 1.507  \n",
      "iter: 800 dis_loss: 1.046 gen_loss: 1.023  \n",
      "iter: 900 dis_loss: 0.912 gen_loss: 1.330  \n",
      "iter: 1000 dis_loss: 0.989 gen_loss: 1.190  \n",
      "iter: 1100 dis_loss: 0.952 gen_loss: 1.511  \n",
      "iter: 1200 dis_loss: 0.929 gen_loss: 1.311  \n",
      "iter: 1300 dis_loss: 0.988 gen_loss: 1.236  \n",
      "iter: 1400 dis_loss: 1.222 gen_loss: 1.437  \n",
      "iter: 1500 dis_loss: 0.962 gen_loss: 1.441  \n",
      "iter: 1600 dis_loss: 1.103 gen_loss: 1.274  \n",
      "iter: 1700 dis_loss: 1.036 gen_loss: 1.142  \n",
      "iter: 1800 dis_loss: 0.939 gen_loss: 1.060  \n",
      "iter: 1900 dis_loss: 1.177 gen_loss: 1.309  \n",
      "iter: 2000 dis_loss: 1.005 gen_loss: 1.332  \n",
      "iter: 2100 dis_loss: 1.026 gen_loss: 1.379  \n",
      "iter: 2200 dis_loss: 1.000 gen_loss: 0.980  \n",
      "iter: 2300 dis_loss: 1.160 gen_loss: 1.283  \n",
      "iter: 2400 dis_loss: 1.130 gen_loss: 0.937  \n",
      "iter: 2500 dis_loss: 0.901 gen_loss: 1.396  \n",
      "iter: 2600 dis_loss: 1.257 gen_loss: 1.588  \n",
      "iter: 2700 dis_loss: 1.093 gen_loss: 1.324  \n",
      "iter: 2800 dis_loss: 1.049 gen_loss: 1.448  \n",
      "iter: 2900 dis_loss: 0.992 gen_loss: 1.452  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.101 gen_loss: 1.220  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 dis_loss: 1.208 gen_loss: 1.235  \n",
      "iter: 200 dis_loss: 1.063 gen_loss: 1.378  \n",
      "iter: 300 dis_loss: 0.942 gen_loss: 1.403  \n",
      "iter: 400 dis_loss: 0.963 gen_loss: 1.020  \n",
      "iter: 500 dis_loss: 0.954 gen_loss: 1.242  \n",
      "iter: 600 dis_loss: 1.036 gen_loss: 1.372  \n",
      "iter: 700 dis_loss: 0.931 gen_loss: 1.001  \n",
      "iter: 800 dis_loss: 0.980 gen_loss: 1.355  \n",
      "iter: 900 dis_loss: 1.104 gen_loss: 1.596  \n",
      "iter: 1000 dis_loss: 1.036 gen_loss: 1.260  \n",
      "iter: 1100 dis_loss: 1.020 gen_loss: 1.201  \n",
      "iter: 1200 dis_loss: 1.048 gen_loss: 1.077  \n",
      "iter: 1300 dis_loss: 1.168 gen_loss: 1.150  \n",
      "iter: 1400 dis_loss: 1.142 gen_loss: 1.217  \n",
      "iter: 1500 dis_loss: 0.946 gen_loss: 1.558  \n",
      "iter: 1600 dis_loss: 1.082 gen_loss: 1.021  \n",
      "iter: 1700 dis_loss: 1.128 gen_loss: 1.290  \n",
      "iter: 1800 dis_loss: 1.132 gen_loss: 1.193  \n",
      "iter: 1900 dis_loss: 1.046 gen_loss: 1.228  \n",
      "iter: 2000 dis_loss: 1.007 gen_loss: 1.152  \n",
      "iter: 2100 dis_loss: 0.919 gen_loss: 1.378  \n",
      "iter: 2200 dis_loss: 0.963 gen_loss: 1.217  \n",
      "iter: 2300 dis_loss: 1.130 gen_loss: 1.243  \n",
      "iter: 2400 dis_loss: 0.986 gen_loss: 1.194  \n",
      "iter: 2500 dis_loss: 1.105 gen_loss: 1.193  \n",
      "iter: 2600 dis_loss: 0.986 gen_loss: 1.084  \n",
      "iter: 2700 dis_loss: 1.000 gen_loss: 1.598  \n",
      "iter: 2800 dis_loss: 1.190 gen_loss: 1.413  \n",
      "iter: 2900 dis_loss: 1.163 gen_loss: 1.091  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.085 gen_loss: 1.578  \n",
      "iter: 100 dis_loss: 1.004 gen_loss: 1.338  \n",
      "iter: 200 dis_loss: 1.063 gen_loss: 1.258  \n",
      "iter: 300 dis_loss: 1.158 gen_loss: 1.081  \n",
      "iter: 400 dis_loss: 1.045 gen_loss: 1.411  \n",
      "iter: 500 dis_loss: 1.035 gen_loss: 1.405  \n",
      "iter: 600 dis_loss: 1.159 gen_loss: 1.272  \n",
      "iter: 700 dis_loss: 1.144 gen_loss: 1.093  \n",
      "iter: 800 dis_loss: 1.224 gen_loss: 1.309  \n",
      "iter: 900 dis_loss: 1.034 gen_loss: 0.966  \n",
      "iter: 1000 dis_loss: 1.106 gen_loss: 1.027  \n",
      "iter: 1100 dis_loss: 1.002 gen_loss: 1.302  \n",
      "iter: 1200 dis_loss: 1.153 gen_loss: 1.355  \n",
      "iter: 1300 dis_loss: 1.153 gen_loss: 1.005  \n",
      "iter: 1400 dis_loss: 1.078 gen_loss: 1.088  \n",
      "iter: 1500 dis_loss: 1.096 gen_loss: 1.390  \n",
      "iter: 1600 dis_loss: 1.116 gen_loss: 1.130  \n",
      "iter: 1700 dis_loss: 1.005 gen_loss: 1.100  \n",
      "iter: 1800 dis_loss: 1.109 gen_loss: 1.353  \n",
      "iter: 1900 dis_loss: 1.210 gen_loss: 1.011  \n",
      "iter: 2000 dis_loss: 1.033 gen_loss: 1.635  \n",
      "iter: 2100 dis_loss: 1.046 gen_loss: 1.362  \n",
      "iter: 2200 dis_loss: 1.087 gen_loss: 0.973  \n",
      "iter: 2300 dis_loss: 1.087 gen_loss: 1.256  \n",
      "iter: 2400 dis_loss: 1.118 gen_loss: 1.164  \n",
      "iter: 2500 dis_loss: 1.052 gen_loss: 1.322  \n",
      "iter: 2600 dis_loss: 1.124 gen_loss: 1.310  \n",
      "iter: 2700 dis_loss: 1.181 gen_loss: 1.360  \n",
      "iter: 2800 dis_loss: 1.172 gen_loss: 1.131  \n",
      "iter: 2900 dis_loss: 1.046 gen_loss: 1.191  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.069 gen_loss: 1.012  \n",
      "iter: 100 dis_loss: 1.113 gen_loss: 0.904  \n",
      "iter: 200 dis_loss: 1.060 gen_loss: 1.245  \n",
      "iter: 300 dis_loss: 1.159 gen_loss: 1.273  \n",
      "iter: 400 dis_loss: 1.035 gen_loss: 1.085  \n",
      "iter: 500 dis_loss: 1.214 gen_loss: 1.054  \n",
      "iter: 600 dis_loss: 1.046 gen_loss: 1.181  \n",
      "iter: 700 dis_loss: 1.046 gen_loss: 1.317  \n",
      "iter: 800 dis_loss: 0.934 gen_loss: 1.149  \n",
      "iter: 900 dis_loss: 0.936 gen_loss: 1.256  \n",
      "iter: 1000 dis_loss: 1.240 gen_loss: 1.272  \n",
      "iter: 1100 dis_loss: 1.170 gen_loss: 1.064  \n",
      "iter: 1200 dis_loss: 1.106 gen_loss: 1.145  \n",
      "iter: 1300 dis_loss: 1.094 gen_loss: 1.081  \n",
      "iter: 1400 dis_loss: 0.922 gen_loss: 1.138  \n",
      "iter: 1500 dis_loss: 1.009 gen_loss: 1.150  \n",
      "iter: 1600 dis_loss: 1.131 gen_loss: 1.317  \n",
      "iter: 1700 dis_loss: 1.137 gen_loss: 1.130  \n",
      "iter: 1800 dis_loss: 1.049 gen_loss: 1.412  \n",
      "iter: 1900 dis_loss: 1.195 gen_loss: 1.424  \n",
      "iter: 2000 dis_loss: 0.966 gen_loss: 1.190  \n",
      "iter: 2100 dis_loss: 1.375 gen_loss: 1.327  \n",
      "iter: 2200 dis_loss: 1.070 gen_loss: 1.220  \n",
      "iter: 2300 dis_loss: 1.250 gen_loss: 1.152  \n",
      "iter: 2400 dis_loss: 1.029 gen_loss: 1.116  \n",
      "iter: 2500 dis_loss: 1.399 gen_loss: 0.962  \n",
      "iter: 2600 dis_loss: 1.116 gen_loss: 1.581  \n",
      "iter: 2700 dis_loss: 1.220 gen_loss: 1.288  \n",
      "iter: 2800 dis_loss: 1.021 gen_loss: 1.383  \n",
      "iter: 2900 dis_loss: 1.140 gen_loss: 1.070  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.227 gen_loss: 1.247  \n",
      "iter: 100 dis_loss: 1.312 gen_loss: 1.227  \n",
      "iter: 200 dis_loss: 1.185 gen_loss: 0.950  \n",
      "iter: 300 dis_loss: 1.145 gen_loss: 1.269  \n",
      "iter: 400 dis_loss: 0.951 gen_loss: 0.910  \n",
      "iter: 500 dis_loss: 1.136 gen_loss: 0.956  \n",
      "iter: 600 dis_loss: 1.300 gen_loss: 1.206  \n",
      "iter: 700 dis_loss: 1.028 gen_loss: 1.254  \n",
      "iter: 800 dis_loss: 0.903 gen_loss: 1.378  \n",
      "iter: 900 dis_loss: 1.027 gen_loss: 1.473  \n",
      "iter: 1000 dis_loss: 1.046 gen_loss: 1.344  \n",
      "iter: 1100 dis_loss: 1.111 gen_loss: 1.102  \n",
      "iter: 1200 dis_loss: 1.133 gen_loss: 1.028  \n",
      "iter: 1300 dis_loss: 1.121 gen_loss: 0.929  \n",
      "iter: 1400 dis_loss: 1.201 gen_loss: 1.016  \n",
      "iter: 1500 dis_loss: 1.062 gen_loss: 1.124  \n",
      "iter: 1600 dis_loss: 1.037 gen_loss: 1.295  \n",
      "iter: 1700 dis_loss: 1.141 gen_loss: 1.360  \n",
      "iter: 1800 dis_loss: 1.203 gen_loss: 1.414  \n",
      "iter: 1900 dis_loss: 1.075 gen_loss: 1.273  \n",
      "iter: 2000 dis_loss: 1.257 gen_loss: 1.153  \n",
      "iter: 2100 dis_loss: 1.181 gen_loss: 1.101  \n",
      "iter: 2200 dis_loss: 1.018 gen_loss: 1.272  \n",
      "iter: 2300 dis_loss: 1.257 gen_loss: 1.130  \n",
      "iter: 2400 dis_loss: 1.237 gen_loss: 1.488  \n",
      "iter: 2500 dis_loss: 0.950 gen_loss: 1.231  \n",
      "iter: 2600 dis_loss: 1.170 gen_loss: 1.204  \n",
      "iter: 2700 dis_loss: 1.097 gen_loss: 1.145  \n",
      "iter: 2800 dis_loss: 1.268 gen_loss: 1.267  \n",
      "iter: 2900 dis_loss: 1.037 gen_loss: 1.102  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.119 gen_loss: 1.097  \n",
      "iter: 100 dis_loss: 1.280 gen_loss: 1.171  \n",
      "iter: 200 dis_loss: 1.003 gen_loss: 1.260  \n",
      "iter: 300 dis_loss: 1.061 gen_loss: 1.366  \n",
      "iter: 400 dis_loss: 1.089 gen_loss: 1.194  \n",
      "iter: 500 dis_loss: 0.962 gen_loss: 1.221  \n",
      "iter: 600 dis_loss: 1.067 gen_loss: 1.235  \n",
      "iter: 700 dis_loss: 1.209 gen_loss: 1.294  \n",
      "iter: 800 dis_loss: 1.034 gen_loss: 1.169  \n",
      "iter: 900 dis_loss: 1.158 gen_loss: 1.003  \n",
      "iter: 1000 dis_loss: 1.209 gen_loss: 1.166  \n",
      "iter: 1100 dis_loss: 1.010 gen_loss: 1.289  \n",
      "iter: 1200 dis_loss: 1.171 gen_loss: 1.263  \n",
      "iter: 1300 dis_loss: 1.050 gen_loss: 1.127  \n",
      "iter: 1400 dis_loss: 1.259 gen_loss: 1.038  \n",
      "iter: 1500 dis_loss: 1.267 gen_loss: 1.053  \n",
      "iter: 1600 dis_loss: 1.193 gen_loss: 1.179  \n",
      "iter: 1700 dis_loss: 1.213 gen_loss: 0.966  \n",
      "iter: 1800 dis_loss: 1.259 gen_loss: 1.031  \n",
      "iter: 1900 dis_loss: 1.145 gen_loss: 1.099  \n",
      "iter: 2000 dis_loss: 1.240 gen_loss: 1.143  \n",
      "iter: 2100 dis_loss: 1.062 gen_loss: 1.187  \n",
      "iter: 2200 dis_loss: 1.161 gen_loss: 1.070  \n",
      "iter: 2300 dis_loss: 1.270 gen_loss: 1.230  \n",
      "iter: 2400 dis_loss: 1.052 gen_loss: 1.132  \n",
      "iter: 2500 dis_loss: 0.998 gen_loss: 1.193  \n",
      "iter: 2600 dis_loss: 1.090 gen_loss: 1.022  \n",
      "iter: 2700 dis_loss: 1.082 gen_loss: 1.015  \n",
      "iter: 2800 dis_loss: 1.103 gen_loss: 1.401  \n",
      "iter: 2900 dis_loss: 0.932 gen_loss: 1.355  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.156 gen_loss: 1.218  \n",
      "iter: 100 dis_loss: 1.051 gen_loss: 1.175  \n",
      "iter: 200 dis_loss: 1.238 gen_loss: 1.073  \n",
      "iter: 300 dis_loss: 1.139 gen_loss: 1.376  \n",
      "iter: 400 dis_loss: 1.074 gen_loss: 1.361  \n",
      "iter: 500 dis_loss: 1.126 gen_loss: 1.266  \n",
      "iter: 600 dis_loss: 1.050 gen_loss: 0.933  \n",
      "iter: 700 dis_loss: 1.082 gen_loss: 1.288  \n",
      "iter: 800 dis_loss: 1.184 gen_loss: 0.836  \n",
      "iter: 900 dis_loss: 1.136 gen_loss: 1.229  \n",
      "iter: 1000 dis_loss: 0.975 gen_loss: 1.327  \n",
      "iter: 1100 dis_loss: 1.260 gen_loss: 1.082  \n",
      "iter: 1200 dis_loss: 1.215 gen_loss: 0.887  \n",
      "iter: 1300 dis_loss: 1.035 gen_loss: 1.101  \n",
      "iter: 1400 dis_loss: 1.168 gen_loss: 1.206  \n",
      "iter: 1500 dis_loss: 1.178 gen_loss: 1.097  \n",
      "iter: 1600 dis_loss: 1.118 gen_loss: 1.277  \n",
      "iter: 1700 dis_loss: 1.062 gen_loss: 1.521  \n",
      "iter: 1800 dis_loss: 1.125 gen_loss: 0.835  \n",
      "iter: 1900 dis_loss: 1.105 gen_loss: 1.223  \n",
      "iter: 2000 dis_loss: 1.185 gen_loss: 1.050  \n",
      "iter: 2100 dis_loss: 1.190 gen_loss: 1.077  \n",
      "iter: 2200 dis_loss: 1.002 gen_loss: 1.041  \n",
      "iter: 2300 dis_loss: 1.011 gen_loss: 1.108  \n",
      "iter: 2400 dis_loss: 1.019 gen_loss: 1.178  \n",
      "iter: 2500 dis_loss: 1.283 gen_loss: 1.075  \n",
      "iter: 2600 dis_loss: 1.042 gen_loss: 1.523  \n",
      "iter: 2700 dis_loss: 1.212 gen_loss: 1.104  \n",
      "iter: 2800 dis_loss: 1.189 gen_loss: 1.121  \n",
      "iter: 2900 dis_loss: 1.160 gen_loss: 1.183  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.243 gen_loss: 0.817  \n",
      "iter: 100 dis_loss: 0.961 gen_loss: 1.344  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 200 dis_loss: 1.123 gen_loss: 1.065  \n",
      "iter: 300 dis_loss: 1.154 gen_loss: 1.014  \n",
      "iter: 400 dis_loss: 1.138 gen_loss: 0.873  \n",
      "iter: 500 dis_loss: 1.004 gen_loss: 0.955  \n",
      "iter: 600 dis_loss: 1.007 gen_loss: 1.353  \n",
      "iter: 700 dis_loss: 1.193 gen_loss: 0.850  \n",
      "iter: 800 dis_loss: 1.106 gen_loss: 1.121  \n",
      "iter: 900 dis_loss: 1.124 gen_loss: 0.968  \n",
      "iter: 1000 dis_loss: 1.164 gen_loss: 1.177  \n",
      "iter: 1100 dis_loss: 1.125 gen_loss: 0.955  \n",
      "iter: 1200 dis_loss: 1.192 gen_loss: 1.092  \n",
      "iter: 1300 dis_loss: 1.268 gen_loss: 1.253  \n",
      "iter: 1400 dis_loss: 0.992 gen_loss: 0.987  \n",
      "iter: 1500 dis_loss: 1.026 gen_loss: 1.082  \n",
      "iter: 1600 dis_loss: 1.076 gen_loss: 1.118  \n",
      "iter: 1700 dis_loss: 1.125 gen_loss: 1.119  \n",
      "iter: 1800 dis_loss: 0.947 gen_loss: 1.187  \n",
      "iter: 1900 dis_loss: 1.069 gen_loss: 1.250  \n",
      "iter: 2000 dis_loss: 1.079 gen_loss: 1.305  \n",
      "iter: 2100 dis_loss: 1.137 gen_loss: 1.172  \n",
      "iter: 2200 dis_loss: 1.062 gen_loss: 1.193  \n",
      "iter: 2300 dis_loss: 1.191 gen_loss: 1.005  \n",
      "iter: 2400 dis_loss: 1.190 gen_loss: 1.162  \n",
      "iter: 2500 dis_loss: 1.107 gen_loss: 1.028  \n",
      "iter: 2600 dis_loss: 1.129 gen_loss: 1.182  \n",
      "iter: 2700 dis_loss: 1.117 gen_loss: 1.333  \n",
      "iter: 2800 dis_loss: 1.174 gen_loss: 0.998  \n",
      "iter: 2900 dis_loss: 0.996 gen_loss: 1.035  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.227 gen_loss: 1.199  \n",
      "iter: 100 dis_loss: 1.025 gen_loss: 1.099  \n",
      "iter: 200 dis_loss: 1.133 gen_loss: 1.108  \n",
      "iter: 300 dis_loss: 1.209 gen_loss: 1.326  \n",
      "iter: 400 dis_loss: 1.176 gen_loss: 1.543  \n",
      "iter: 500 dis_loss: 1.160 gen_loss: 1.174  \n",
      "iter: 600 dis_loss: 1.086 gen_loss: 1.170  \n",
      "iter: 700 dis_loss: 1.130 gen_loss: 1.173  \n",
      "iter: 800 dis_loss: 1.014 gen_loss: 1.094  \n",
      "iter: 900 dis_loss: 1.264 gen_loss: 0.924  \n",
      "iter: 1000 dis_loss: 1.077 gen_loss: 1.306  \n",
      "iter: 1100 dis_loss: 0.968 gen_loss: 1.037  \n",
      "iter: 1200 dis_loss: 1.142 gen_loss: 0.965  \n",
      "iter: 1300 dis_loss: 1.057 gen_loss: 1.122  \n",
      "iter: 1400 dis_loss: 1.023 gen_loss: 1.063  \n",
      "iter: 1500 dis_loss: 1.274 gen_loss: 1.065  \n",
      "iter: 1600 dis_loss: 0.965 gen_loss: 0.902  \n",
      "iter: 1700 dis_loss: 1.144 gen_loss: 1.044  \n",
      "iter: 1800 dis_loss: 1.272 gen_loss: 1.077  \n",
      "iter: 1900 dis_loss: 1.092 gen_loss: 1.436  \n",
      "iter: 2000 dis_loss: 1.149 gen_loss: 1.158  \n",
      "iter: 2100 dis_loss: 1.072 gen_loss: 1.338  \n",
      "iter: 2200 dis_loss: 1.123 gen_loss: 0.924  \n",
      "iter: 2300 dis_loss: 1.398 gen_loss: 1.059  \n",
      "iter: 2400 dis_loss: 1.083 gen_loss: 0.944  \n",
      "iter: 2500 dis_loss: 1.187 gen_loss: 1.017  \n",
      "iter: 2600 dis_loss: 1.005 gen_loss: 1.338  \n",
      "iter: 2700 dis_loss: 1.208 gen_loss: 1.158  \n",
      "iter: 2800 dis_loss: 1.075 gen_loss: 1.041  \n",
      "iter: 2900 dis_loss: 1.127 gen_loss: 1.301  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.173 gen_loss: 1.289  \n",
      "iter: 100 dis_loss: 1.239 gen_loss: 1.222  \n",
      "iter: 200 dis_loss: 1.058 gen_loss: 1.106  \n",
      "iter: 300 dis_loss: 1.207 gen_loss: 1.263  \n",
      "iter: 400 dis_loss: 0.984 gen_loss: 1.023  \n",
      "iter: 500 dis_loss: 1.236 gen_loss: 0.978  \n",
      "iter: 600 dis_loss: 1.083 gen_loss: 1.062  \n",
      "iter: 700 dis_loss: 1.149 gen_loss: 1.174  \n",
      "iter: 800 dis_loss: 1.197 gen_loss: 1.065  \n",
      "iter: 900 dis_loss: 1.256 gen_loss: 1.042  \n",
      "iter: 1000 dis_loss: 1.157 gen_loss: 1.263  \n",
      "iter: 1100 dis_loss: 1.211 gen_loss: 1.186  \n",
      "iter: 1200 dis_loss: 1.108 gen_loss: 1.112  \n",
      "iter: 1300 dis_loss: 1.005 gen_loss: 1.146  \n",
      "iter: 1400 dis_loss: 1.174 gen_loss: 1.045  \n",
      "iter: 1500 dis_loss: 1.301 gen_loss: 1.347  \n",
      "iter: 1600 dis_loss: 1.105 gen_loss: 0.960  \n",
      "iter: 1700 dis_loss: 1.016 gen_loss: 1.052  \n",
      "iter: 1800 dis_loss: 1.119 gen_loss: 1.138  \n",
      "iter: 1900 dis_loss: 1.317 gen_loss: 1.290  \n",
      "iter: 2000 dis_loss: 1.348 gen_loss: 1.481  \n",
      "iter: 2100 dis_loss: 1.132 gen_loss: 1.171  \n",
      "iter: 2200 dis_loss: 1.257 gen_loss: 0.800  \n",
      "iter: 2300 dis_loss: 1.182 gen_loss: 1.075  \n",
      "iter: 2400 dis_loss: 1.301 gen_loss: 1.226  \n",
      "iter: 2500 dis_loss: 0.956 gen_loss: 1.316  \n",
      "iter: 2600 dis_loss: 1.082 gen_loss: 1.319  \n",
      "iter: 2700 dis_loss: 1.131 gen_loss: 0.980  \n",
      "iter: 2800 dis_loss: 1.192 gen_loss: 0.893  \n",
      "iter: 2900 dis_loss: 1.192 gen_loss: 1.185  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.204 gen_loss: 0.915  \n",
      "iter: 100 dis_loss: 1.053 gen_loss: 1.000  \n",
      "iter: 200 dis_loss: 1.120 gen_loss: 1.014  \n",
      "iter: 300 dis_loss: 1.166 gen_loss: 1.118  \n",
      "iter: 400 dis_loss: 1.101 gen_loss: 0.910  \n",
      "iter: 500 dis_loss: 1.125 gen_loss: 1.060  \n",
      "iter: 600 dis_loss: 1.049 gen_loss: 1.114  \n",
      "iter: 700 dis_loss: 1.148 gen_loss: 1.264  \n",
      "iter: 800 dis_loss: 1.244 gen_loss: 1.089  \n",
      "iter: 900 dis_loss: 1.080 gen_loss: 1.065  \n",
      "iter: 1000 dis_loss: 1.045 gen_loss: 1.090  \n",
      "iter: 1100 dis_loss: 1.172 gen_loss: 1.082  \n",
      "iter: 1200 dis_loss: 1.071 gen_loss: 1.160  \n",
      "iter: 1300 dis_loss: 1.142 gen_loss: 1.191  \n",
      "iter: 1400 dis_loss: 1.000 gen_loss: 1.151  \n",
      "iter: 1500 dis_loss: 1.157 gen_loss: 1.061  \n",
      "iter: 1600 dis_loss: 1.009 gen_loss: 1.163  \n",
      "iter: 1700 dis_loss: 0.998 gen_loss: 1.384  \n",
      "iter: 1800 dis_loss: 1.137 gen_loss: 1.382  \n",
      "iter: 1900 dis_loss: 1.103 gen_loss: 1.269  \n",
      "iter: 2000 dis_loss: 1.044 gen_loss: 1.097  \n",
      "iter: 2100 dis_loss: 1.012 gen_loss: 1.215  \n",
      "iter: 2200 dis_loss: 0.985 gen_loss: 1.020  \n",
      "iter: 2300 dis_loss: 1.215 gen_loss: 1.021  \n",
      "iter: 2400 dis_loss: 1.009 gen_loss: 1.334  \n",
      "iter: 2500 dis_loss: 1.156 gen_loss: 0.897  \n",
      "iter: 2600 dis_loss: 1.221 gen_loss: 1.100  \n",
      "iter: 2700 dis_loss: 1.013 gen_loss: 1.172  \n",
      "iter: 2800 dis_loss: 1.018 gen_loss: 1.042  \n",
      "iter: 2900 dis_loss: 1.181 gen_loss: 1.450  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 0.993 gen_loss: 1.141  \n",
      "iter: 100 dis_loss: 1.260 gen_loss: 1.417  \n",
      "iter: 200 dis_loss: 1.137 gen_loss: 1.348  \n",
      "iter: 300 dis_loss: 1.022 gen_loss: 1.207  \n",
      "iter: 400 dis_loss: 1.327 gen_loss: 1.177  \n",
      "iter: 500 dis_loss: 1.054 gen_loss: 1.013  \n",
      "iter: 600 dis_loss: 1.006 gen_loss: 1.297  \n",
      "iter: 700 dis_loss: 1.112 gen_loss: 1.127  \n",
      "iter: 800 dis_loss: 1.015 gen_loss: 1.175  \n",
      "iter: 900 dis_loss: 1.051 gen_loss: 1.114  \n",
      "iter: 1000 dis_loss: 1.082 gen_loss: 1.230  \n",
      "iter: 1100 dis_loss: 0.990 gen_loss: 0.997  \n",
      "iter: 1200 dis_loss: 1.085 gen_loss: 0.960  \n",
      "iter: 1300 dis_loss: 1.012 gen_loss: 1.197  \n",
      "iter: 1400 dis_loss: 1.100 gen_loss: 1.124  \n",
      "iter: 1500 dis_loss: 1.120 gen_loss: 1.376  \n",
      "iter: 1600 dis_loss: 1.218 gen_loss: 1.102  \n",
      "iter: 1700 dis_loss: 1.065 gen_loss: 1.113  \n",
      "iter: 1800 dis_loss: 1.037 gen_loss: 1.046  \n",
      "iter: 1900 dis_loss: 1.122 gen_loss: 1.014  \n",
      "iter: 2000 dis_loss: 1.079 gen_loss: 1.181  \n",
      "iter: 2100 dis_loss: 0.996 gen_loss: 1.005  \n",
      "iter: 2200 dis_loss: 1.196 gen_loss: 1.269  \n",
      "iter: 2300 dis_loss: 1.215 gen_loss: 1.288  \n",
      "iter: 2400 dis_loss: 0.958 gen_loss: 1.326  \n",
      "iter: 2500 dis_loss: 1.191 gen_loss: 1.209  \n",
      "iter: 2600 dis_loss: 1.070 gen_loss: 1.014  \n",
      "iter: 2700 dis_loss: 1.048 gen_loss: 1.220  \n",
      "iter: 2800 dis_loss: 0.984 gen_loss: 1.615  \n",
      "iter: 2900 dis_loss: 1.283 gen_loss: 1.044  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.166 gen_loss: 1.305  \n",
      "iter: 100 dis_loss: 1.237 gen_loss: 0.918  \n",
      "iter: 200 dis_loss: 1.139 gen_loss: 0.990  \n",
      "iter: 300 dis_loss: 1.156 gen_loss: 0.944  \n",
      "iter: 400 dis_loss: 1.133 gen_loss: 1.239  \n",
      "iter: 500 dis_loss: 1.252 gen_loss: 1.218  \n",
      "iter: 600 dis_loss: 1.103 gen_loss: 1.075  \n",
      "iter: 700 dis_loss: 1.017 gen_loss: 1.069  \n",
      "iter: 800 dis_loss: 1.190 gen_loss: 0.947  \n",
      "iter: 900 dis_loss: 1.203 gen_loss: 1.068  \n",
      "iter: 1000 dis_loss: 1.112 gen_loss: 1.108  \n",
      "iter: 1100 dis_loss: 1.200 gen_loss: 1.101  \n",
      "iter: 1200 dis_loss: 1.011 gen_loss: 1.453  \n",
      "iter: 1300 dis_loss: 1.219 gen_loss: 1.178  \n",
      "iter: 1400 dis_loss: 1.187 gen_loss: 1.162  \n",
      "iter: 1500 dis_loss: 1.078 gen_loss: 1.433  \n",
      "iter: 1600 dis_loss: 1.002 gen_loss: 1.024  \n",
      "iter: 1700 dis_loss: 1.015 gen_loss: 1.095  \n",
      "iter: 1800 dis_loss: 0.937 gen_loss: 1.130  \n",
      "iter: 1900 dis_loss: 1.191 gen_loss: 0.990  \n",
      "iter: 2000 dis_loss: 1.063 gen_loss: 1.151  \n",
      "iter: 2100 dis_loss: 1.026 gen_loss: 1.035  \n",
      "iter: 2200 dis_loss: 1.125 gen_loss: 1.395  \n",
      "iter: 2300 dis_loss: 1.163 gen_loss: 1.110  \n",
      "iter: 2400 dis_loss: 1.064 gen_loss: 0.868  \n",
      "iter: 2500 dis_loss: 1.239 gen_loss: 0.931  \n",
      "iter: 2600 dis_loss: 1.038 gen_loss: 1.332  \n",
      "iter: 2700 dis_loss: 1.214 gen_loss: 1.193  \n",
      "iter: 2800 dis_loss: 0.952 gen_loss: 1.308  \n",
      "iter: 2900 dis_loss: 1.100 gen_loss: 1.226  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 0.961 gen_loss: 1.073  \n",
      "iter: 100 dis_loss: 1.068 gen_loss: 1.124  \n",
      "iter: 200 dis_loss: 1.196 gen_loss: 1.176  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 300 dis_loss: 1.063 gen_loss: 1.216  \n",
      "iter: 400 dis_loss: 1.129 gen_loss: 1.164  \n",
      "iter: 500 dis_loss: 0.963 gen_loss: 0.995  \n",
      "iter: 600 dis_loss: 1.011 gen_loss: 1.202  \n",
      "iter: 700 dis_loss: 1.140 gen_loss: 0.977  \n",
      "iter: 800 dis_loss: 1.044 gen_loss: 1.122  \n",
      "iter: 900 dis_loss: 1.082 gen_loss: 1.258  \n",
      "iter: 1000 dis_loss: 0.997 gen_loss: 1.019  \n",
      "iter: 1100 dis_loss: 1.101 gen_loss: 1.118  \n",
      "iter: 1200 dis_loss: 1.159 gen_loss: 0.918  \n",
      "iter: 1300 dis_loss: 1.096 gen_loss: 1.067  \n",
      "iter: 1400 dis_loss: 1.322 gen_loss: 1.312  \n",
      "iter: 1500 dis_loss: 1.040 gen_loss: 1.217  \n",
      "iter: 1600 dis_loss: 1.091 gen_loss: 1.264  \n",
      "iter: 1700 dis_loss: 1.240 gen_loss: 1.195  \n",
      "iter: 1800 dis_loss: 1.188 gen_loss: 0.939  \n",
      "iter: 1900 dis_loss: 0.994 gen_loss: 1.030  \n",
      "iter: 2000 dis_loss: 1.111 gen_loss: 1.331  \n",
      "iter: 2100 dis_loss: 1.133 gen_loss: 1.582  \n",
      "iter: 2200 dis_loss: 1.087 gen_loss: 1.041  \n",
      "iter: 2300 dis_loss: 1.230 gen_loss: 0.999  \n",
      "iter: 2400 dis_loss: 1.064 gen_loss: 1.399  \n",
      "iter: 2500 dis_loss: 0.991 gen_loss: 1.060  \n",
      "iter: 2600 dis_loss: 1.204 gen_loss: 1.025  \n",
      "iter: 2700 dis_loss: 1.058 gen_loss: 1.258  \n",
      "iter: 2800 dis_loss: 1.173 gen_loss: 1.203  \n",
      "iter: 2900 dis_loss: 1.122 gen_loss: 1.292  \n",
      "One Epoch completed\n",
      "iter:   0 dis_loss: 1.192 gen_loss: 1.354  \n",
      "iter: 100 dis_loss: 0.969 gen_loss: 1.077  \n",
      "iter: 200 dis_loss: 1.372 gen_loss: 1.262  \n",
      "iter: 300 dis_loss: 1.113 gen_loss: 1.065  \n",
      "iter: 400 dis_loss: 1.373 gen_loss: 0.957  \n",
      "iter: 500 dis_loss: 1.153 gen_loss: 1.162  \n",
      "iter: 600 dis_loss: 1.036 gen_loss: 1.007  \n",
      "iter: 700 dis_loss: 1.028 gen_loss: 1.164  \n",
      "iter: 800 dis_loss: 1.151 gen_loss: 1.189  \n",
      "iter: 900 dis_loss: 0.963 gen_loss: 0.955  \n",
      "iter: 1000 dis_loss: 0.923 gen_loss: 1.353  \n",
      "iter: 1100 dis_loss: 0.990 gen_loss: 1.370  \n",
      "iter: 1200 dis_loss: 1.104 gen_loss: 1.149  \n",
      "iter: 1300 dis_loss: 1.083 gen_loss: 1.179  \n",
      "iter: 1400 dis_loss: 1.061 gen_loss: 1.057  \n",
      "iter: 1500 dis_loss: 1.216 gen_loss: 1.309  \n",
      "iter: 1600 dis_loss: 1.166 gen_loss: 1.247  \n",
      "iter: 1700 dis_loss: 1.073 gen_loss: 1.308  \n",
      "iter: 1800 dis_loss: 1.202 gen_loss: 0.909  \n",
      "iter: 1900 dis_loss: 1.051 gen_loss: 1.532  \n",
      "iter: 2000 dis_loss: 1.127 gen_loss: 1.317  \n",
      "iter: 2100 dis_loss: 1.199 gen_loss: 1.062  \n",
      "iter: 2200 dis_loss: 1.007 gen_loss: 0.995  \n",
      "iter: 2300 dis_loss: 1.155 gen_loss: 1.023  \n",
      "iter: 2400 dis_loss: 1.051 gen_loss: 1.046  \n",
      "iter: 2500 dis_loss: 1.199 gen_loss: 1.092  \n",
      "iter: 2600 dis_loss: 1.117 gen_loss: 1.124  \n",
      "iter: 2700 dis_loss: 1.067 gen_loss: 1.276  \n",
      "iter: 2800 dis_loss: 1.035 gen_loss: 1.020  \n",
      "iter: 2900 dis_loss: 1.079 gen_loss: 1.358  \n",
      "One Epoch completed\n"
     ]
    }
   ],
   "source": [
    "LEARN_RATE = 1e-4\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    dataiter = iter(trainloader)\n",
    "    for i, data in enumerate(dataiter):\n",
    "        true_im, _ = data\n",
    "        dis_optimizer.zero_grad()\n",
    "        gen_optimizer.zero_grad()\n",
    "        # Forward pass 'BATCH_SIZE' number of noise vectors through Generator\n",
    "        noise_outputs = gen1(Variable(torch.randn(BATCH_SIZE,NOISE_DIM)))\n",
    "        # Obtain 'BATCH_SIZE' number of true samples\n",
    "        true_vec = true_im.view(-1,MNIST_DIM)\n",
    "              \n",
    "        # Forward pass \"false\" and true samples through the discriminator\n",
    "        # and calculate the respective terms of discriminator loss\n",
    "        if smooth_labels == 0:\n",
    "            dis_true_loss = criterion_dis(dis1(Variable(true_vec)),Variable(torch.ones([BATCH_SIZE,1])))\n",
    "            dis_false_loss = criterion_dis(dis1(noise_outputs),Variable(torch.zeros([BATCH_SIZE,1])))\n",
    "        else:\n",
    "            dis_true_loss = criterion_dis(dis1(Variable(true_vec)),Variable(0.9*torch.ones([BATCH_SIZE,1])))\n",
    "            dis_false_loss = criterion_dis(dis1(noise_outputs),Variable(0.1*torch.ones([BATCH_SIZE,1])))\n",
    "            \n",
    "        # Calculate discriminator loss and backprop on discriminator params\n",
    "        dis_loss = (dis_true_loss + dis_false_loss)\n",
    "        dis_loss.backward()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        ## Generator update step\n",
    "        dis_optimizer.zero_grad()\n",
    "        gen_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass 'BATCH_SIZE' number of noise vectors through Generator, and the outputs through Discriminator\t\t\n",
    "        noise_outputs = gen1(Variable(torch.randn(BATCH_SIZE,NOISE_DIM)))\n",
    "\n",
    "        # Calculate generator loss and backprop on generator params\n",
    "        if smooth_labels == 0:\n",
    "            gen_loss = criterion_gen(dis1(noise_outputs),Variable(torch.ones([BATCH_SIZE,1])))\n",
    "        else:\n",
    "            gen_loss = criterion_gen(dis1(noise_outputs),Variable(0.9*torch.ones([BATCH_SIZE,1])))    \n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('iter: %3d dis_loss: %.3f gen_loss: %.3f  ' % (i, dis_loss.data, gen_loss.data) )\n",
    "    \n",
    "    print('One Epoch completed')\n",
    "    # Should save the model at this checkpoint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10c969350>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cc664d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at the generated images\n",
    "false_vec = gen1(Variable(torch.randn(20,NOISE_DIM)*2))\n",
    "false_im = false_vec.view(-1,1,28,28)\n",
    "false_im_grid = torchvision.utils.make_grid(false_im.data,nrow = 5)\n",
    "np_im_grid = false_im_grid.numpy()\n",
    "plt.imshow(np.transpose(np_im_grid,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
